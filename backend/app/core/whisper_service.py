"""
whisper_service.py
==================
Nepali Voice Inventory System ‚Äî Audio Transcription + Pre-processing

PERMANENT NUMBER SOLUTION:
  Step 0: Convert Devanagari digit characters (‡•ß‡•®‡•©...) ‚Üí Arabic (123...)
           This handles ANY number of any size, forever.
  Step 1: Exact dict ‚Äî Nepali number words (‡§è‡§ï, ‡§¶‡•Å‡§à, ... ‡§∏‡§Ø) ‚Üí digits
  Step 2: Exact dict ‚Äî items, units, actions
  Step 3: Prefix-tree ‚Äî catches any Devanagari item/action mishear not in dict
  Step 4: Deduplicate repeated canonical tokens

DEVANAGARI PREFIX-TREE (item disambiguation by character):
  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
  ‚îÇ  1st CHAR  ‚Üí  ITEM                                             ‚îÇ
  ‚îÇ  ‡§Ö  ‚Üí Eggs                                                     ‚îÇ
  ‚îÇ  ‡§°  ‚Üí Lentils   (only ‡§°, NOT ‡§¶ ‚Äî see NUMBER SAFETY note)      ‚îÇ
  ‚îÇ  ‡§§  ‚Üí Oil                                                      ‚îÇ
  ‚îÇ  ‡§®  ‚Üí Salt                                                     ‚îÇ
  ‚îÇ  ‡§Æ  ‚Üí Flour  (covers ‡§Æ‡§π‡§ø‡§¶‡§æ, ‡§Æ‡•á‡§¶‡§æ, ‡§Æ‡§à‡§¶‡§æ, ‡§Æ‡§á‡§¶‡§æ, ‡§Æ‡§æ‡§á‡§¶‡§æ, ...)    ‚îÇ
  ‚îÇ  ‡§µ  ‚Üí Turmeric  (‡§µ‡•á‡§∏‡§æ‡§∞ alternate)                             ‚îÇ
  ‚îÇ  ‡§ö + ‡§ö‡§æ ‚Üí Rice                                                 ‚îÇ
  ‚îÇ  ‡§ö + ‡§ö‡§ø + ‡§ö‡§ø‡§® ‚Üí Sugar                                         ‚îÇ
  ‚îÇ  ‡§ö + ‡§ö‡§ø + ‡§ö‡§ø‡§â/‡§ö‡§ø‡•ã ‚Üí Beaten_Rice                              ‚îÇ
  ‚îÇ  ‡§¨ + ‡§¨‡•á ‚Üí Turmeric                                             ‚îÇ
  ‚îÇ  ‡§¨ + ‡§¨‡§ø ‚Üí Biscuits                                             ‚îÇ
  ‚îÇ  ‡§¨ + ‡§¨‡§¢ ‚Üí Add (verb)                                           ‚îÇ
  ‚îÇ                                                                 ‚îÇ
  ‚îÇ  NUMBER SAFETY: ‡§¶-words (‡§¶‡§æ‡§≤ excluded intentionally)           ‚îÇ
  ‚îÇ  All Nepali number words starting with ‡§¶ (‡§¶‡§∂, ‡§¶‡§∏, ‡§¶‡§æ‡§∏, ‡§¶‡•Å‡§à,   ‚îÇ
  ‚îÇ  ‡§¶‡•Å‡§á‡§ü‡§æ) are caught in STEP 1 dict BEFORE the prefix tree runs. ‚îÇ
  ‚îÇ  The prefix tree only sees ‡§¶ if dict missed it ‚Üí Lentils.      ‚îÇ
  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
"""

import re
import whisper


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# DEVANAGARI DIGIT CHARACTERS ‚Üí ARABIC DIGITS
# Handles numbers like ‡•ß‡•¶, ‡•´, ‡•®‡•´, ‡•ß‡•¶‡•¶, ‡•´‡•¶‡•¶ ‚Äî any size, permanently
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

_DEVA_DIGITS = "‡•¶‡•ß‡•®‡•©‡•™‡•´‡•¨‡•≠‡•Æ‡•Ø"

def _convert_devanagari_numerals(text: str) -> str:
    """
    Convert Devanagari digit characters to Arabic digits.
    '‡•ß‡•¶' ‚Üí '10',  '‡•´‡•¶' ‚Üí '50',  '‡•ß‡•®‡•©' ‚Üí '123', etc.
    Works for any number, no upper limit.
    """
    return "".join(
        str(_DEVA_DIGITS.index(ch)) if ch in _DEVA_DIGITS else ch
        for ch in text
    )


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# LAYER 1 ‚Äî EXACT MATCH DICTIONARY
# Numbers MUST come before items/actions ‚Äî number words like ‡§¶‡§∂, ‡§¶‡§∏, ‡§¶‡§æ‡§∏
# start with '‡§¶' which is also the first char of ‡§¶‡§æ‡§≤ (Lentils).
# Dict replaces them first so prefix-tree never sees them as Lentils.
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

CORRECTIONS = {

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # NUMBERS 1‚Äì10 (Devanagari words + Romanized + hallucinations)
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    "‡§è‡§â‡§ü‡§æ": "1", "‡§è‡§ï": "1", "‡§è‡§â": "1",
    "ek": "1", "aek": "1", "euta": "1", "euka": "1",

    "‡§¶‡•Å‡§á‡§ü‡§æ": "2", "‡§¶‡•Å‡§à": "2", "‡§¶‡•ã": "2", "‡§¶‡•Å‡§á": "2",
    "dui": "2", "duitaa": "2",

    "‡§§‡•Ä‡§®": "3", "‡§§‡§ø‡§®": "3", "‡§§‡§ø‡§®‡•Å": "3",
    "teen": "3", "tin": "3", "tiin": "3",

    "‡§ö‡§æ‡§∞": "4", "‡§ö‡§æ‡§∞‡•Å": "4",
    "char": "4", "chaar": "4",

    # ‡§™‡§æ‡§•‡•ç‡§∏ is a real Whisper hallucination for ‡§™‡§æ‡§Å‡§ö
    "‡§™‡§æ‡§Å‡§ö": "5", "‡§™‡§æ‡§ö": "5", "‡§™‡§æ‡§•‡•ç‡§∏": "5",
    "paanch": "5", "panch": "5", "paach": "5", "paanche": "5",

    # ‡§õ in Nepali = BOTH "6" AND "is/are" (grammatical).
    # In inventory questions like "‡§ï‡§§‡§ø ‡§¨‡§æ‡§Å‡§ï‡•Ä ‡§õ" (how much is left?),
    # ‡§õ is always the grammatical "is" ‚Üí map to Check.
    # For the number 6, users say "chha/chah" (Romanized) or type "6" as digit.
    # Standalone Devanagari ‡§õ = grammatical marker ‚Üí Check.
    "‡§õ": "Check",
    "chha": "6", "chah": "6", "chhah": "6",

    "‡§∏‡§æ‡§§": "7", "‡§∏‡§æ‡§æ‡§§": "7",
    "saat": "7", "saath": "7",

    "‡§Ü‡§†": "8",
    "aath": "8", "ath": "8", "aate": "8", "aatha": "8",

    "‡§®‡•å": "9", "‡§®‡•å‡§Ç": "9",
    "nau": "9", "naw": "9", "noo": "9", "nou": "9",

    # 10 ‚Äî IMPORTANT: ‡§¶‡§∂/‡§¶‡§∏/‡§¶‡§æ‡§∏ start with '‡§¶' same as ‡§¶‡§æ‡§≤.
    # Must be caught HERE before prefix tree runs.
    "‡§¶‡§∂": "10", "‡§¶‡§∏": "10", "‡§¶‡§æ‡§∏": "10", "‡§¶‡§æ‡§∂": "10",
    "das": "10", "dass": "10", "dasa": "10", "dash": "10",

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # NUMBERS 11‚Äì19
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    "‡§è‡§ò‡§æ‡§∞": "11", "‡§è‡§ò‡§æ‡§∞‡§æ": "11", "eghar": "11",
    "‡§¨‡§æ‡§π‡•ç‡§∞": "12", "‡§¨‡§æ‡§π‡•ç‡§∞‡§æ": "12", "bahra": "12",
    "‡§§‡•á‡§π‡•ç‡§∞": "13", "‡§§‡•á‡§π‡•ç‡§∞‡§æ": "13", "tehra": "13",
    "‡§ö‡•å‡§ß": "14", "‡§ö‡•å‡§ß‡§æ": "14", "chaudha": "14",
    "‡§™‡§®‡•ç‡§ß‡•ç‡§∞": "15", "‡§™‡§®‡•ç‡§ß‡•ç‡§∞‡§æ": "15", "pandhra": "15",
    "‡§∏‡•ã‡§π‡•ç‡§∞": "16", "‡§∏‡•ã‡§π‡•ç‡§∞‡§æ": "16", "sohra": "16",
    "‡§∏‡§§‡•ç‡§∞": "17", "‡§∏‡§§‡•ç‡§∞‡§æ": "17", "satra": "17",
    "‡§Ö‡§†‡§æ‡§∞": "18", "‡§Ö‡§†‡§æ‡§∞‡§æ": "18", "athara": "18",
    "‡§â‡§®‡•ç‡§®‡§æ‡§á‡§∏": "19", "unnaisa": "19",

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # NUMBERS 20‚Äì100 (tens + most common compounds)
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    "‡§¨‡•Ä‡§∏": "20", "‡§¨‡§ø‡§∏": "20", "bees": "20", "bis": "20",
    "‡§è‡§ï‡§æ‡§á‡§∏": "21", "ekkais": "21",
    "‡§¨‡§æ‡§á‡§∏": "22", "baais": "22",
    "‡§§‡•á‡§á‡§∏": "23", "teis": "23",
    "‡§ö‡•å‡§¨‡•Ä‡§∏": "24", "chaubis": "24",
    "‡§™‡§ö‡•ç‡§ö‡•Ä‡§∏": "25", "‡§™‡§ö‡§ø‡§∏": "25", "pachis": "25",
    "‡§õ‡§¨‡•ç‡§¨‡•Ä‡§∏": "26", "chhabbis": "26",
    "‡§∏‡§§‡•ç‡§§‡§æ‡§á‡§∏": "27", "sattais": "27",
    "‡§Ö‡§ü‡•ç‡§†‡§æ‡§á‡§∏": "28", "atthais": "28",
    "‡§â‡§®‡§®‡•ç‡§§‡•Ä‡§∏": "29", "unantis": "29",

    "‡§§‡•Ä‡§∏": "30", "‡§§‡§ø‡§∏": "30", "tis": "30", "tees": "30",
    "‡§è‡§ï‡§§‡•Ä‡§∏": "31", "‡§è‡§ï‡§§‡§ø‡§∏": "31",
    "‡§¨‡§§‡•ç‡§§‡•Ä‡§∏": "32", "‡§¨‡§§‡•ç‡§§‡§ø‡§∏": "32",
    "‡§§‡•á‡§§‡•ç‡§§‡•Ä‡§∏": "33", "‡§§‡•á‡§§‡•ç‡§§‡§ø‡§∏": "33",
    "‡§ö‡•å‡§Ç‡§§‡•Ä‡§∏": "34", "‡§ö‡•å‡§§‡§ø‡§∏": "34",
    "‡§™‡•à‡§Ç‡§§‡•Ä‡§∏": "35", "‡§™‡•à‡§§‡§ø‡§∏": "35", "paintis": "35",
    "‡§õ‡§§‡•ç‡§§‡•Ä‡§∏": "36", "‡§õ‡§§‡•ç‡§§‡§ø‡§∏": "36",
    "‡§∏‡•à‡§Ç‡§§‡•Ä‡§∏": "37", "‡§∏‡•à‡§§‡§ø‡§∏": "37",
    "‡§Ö‡§†‡§§‡•Ä‡§∏": "38", "‡§Ö‡§†‡§§‡§ø‡§∏": "38",
    "‡§â‡§®‡§®‡•ç‡§ö‡§æ‡§≤‡•Ä‡§∏": "39",

    "‡§ö‡§æ‡§≤‡•Ä‡§∏": "40", "‡§ö‡§æ‡§≤‡§ø‡§∏": "40", "chalis": "40",
    "‡§è‡§ï‡§ö‡§æ‡§≤‡•Ä‡§∏": "41",
    "‡§¨‡§Ø‡§æ‡§≤‡•Ä‡§∏": "42",
    "‡§§‡•ç‡§∞‡§ø‡§ö‡§æ‡§≤‡•Ä‡§∏": "43",
    "‡§ö‡§µ‡§æ‡§≤‡•Ä‡§∏": "44",
    "‡§™‡•à‡§Ç‡§§‡§æ‡§≤‡•Ä‡§∏": "45", "‡§™‡•à‡§§‡§æ‡§≤‡§ø‡§∏": "45", "paintalis": "45",
    "‡§õ‡§Ø‡§æ‡§≤‡•Ä‡§∏": "46",
    "‡§∏‡•à‡§Ç‡§§‡§æ‡§≤‡•Ä‡§∏": "47",
    "‡§Ö‡§†‡§ö‡§æ‡§≤‡•Ä‡§∏": "48",
    "‡§â‡§®‡§®‡•ç‡§™‡§ö‡§æ‡§∏": "49",

    "‡§™‡§ö‡§æ‡§∏": "50", "‡§™‡§ö‡§æ‡§Å‡§∏": "50", "pachas": "50",
    "‡§è‡§ï‡§æ‡§â‡§®‡•ç‡§®": "51",
    "‡§¨‡§æ‡§â‡§®‡•ç‡§®": "52",
    "‡§§‡•ç‡§∞‡§ø‡§™‡§®‡•ç‡§®": "53",
    "‡§ö‡§â‡§®‡•ç‡§®": "54",
    "‡§™‡§ö‡§™‡§®‡•ç‡§®": "55", "‡§™‡§ö‡§™‡§®": "55", "pachpan": "55",
    "‡§õ‡§™‡§®‡•ç‡§®": "56",
    "‡§∏‡§®‡•ç‡§§‡§æ‡§â‡§®‡•ç‡§®": "57",
    "‡§Ö‡§®‡•ç‡§†‡§æ‡§â‡§®‡•ç‡§®": "58",
    "‡§â‡§®‡§∏‡§æ‡§†‡•Ä": "59",

    "‡§∏‡§æ‡§†‡•Ä": "60", "‡§∏‡§æ‡§†‡§ø": "60", "‡§∏‡§æ‡§†‡•ç‡§†‡•Ä": "60", "sathi": "60",
    "‡§è‡§ï‡§∏‡§æ‡§†‡•Ä": "61",
    "‡§¨‡•à‡§∏‡§æ‡§†‡•Ä": "62",
    "‡§§‡•ç‡§∞‡§ø‡§∏‡§æ‡§†‡•Ä": "63",
    "‡§ö‡•å‡§Ç‡§∏‡§æ‡§†‡•Ä": "64",
    "‡§™‡•à‡§Ç‡§∏‡§†‡•Ä": "65", "‡§™‡•à‡§∏‡§†‡§ø": "65", "painsathi": "65",
    "‡§õ‡•à‡§∏‡§†‡•Ä": "66",
    "‡§∏‡§§‡•ç‡§∏‡§†‡•Ä": "67",
    "‡§Ö‡§†‡§∏‡§†‡•Ä": "68",
    "‡§â‡§®‡§π‡§§‡•ç‡§§‡§∞": "69",

    "‡§∏‡§§‡•ç‡§§‡§∞‡•Ä": "70", "‡§∏‡§§‡•ç‡§§‡§∞‡§ø": "70", "sattari": "70",
    "‡§è‡§ï‡§π‡§§‡•ç‡§§‡§∞": "71",
    "‡§¨‡§π‡§§‡•ç‡§§‡§∞": "72",
    "‡§§‡•ç‡§∞‡§ø‡§π‡§§‡•ç‡§§‡§∞": "73",
    "‡§ö‡•å‡§π‡§§‡•ç‡§§‡§∞": "74",
    "‡§™‡§ö‡§π‡§§‡•ç‡§§‡§∞": "75", "pachhattara": "75",
    "‡§õ‡§π‡§§‡•ç‡§§‡§∞": "76",
    "‡§∏‡§§‡•ç‡§π‡§§‡•ç‡§§‡§∞": "77",
    "‡§Ö‡§†‡§π‡§§‡•ç‡§§‡§∞": "78",
    "‡§â‡§®‡§æ‡§∏‡•Ä": "79",

    "‡§Ö‡§∏‡•Ä": "80", "‡§Ö‡§∏‡§ø": "80", "asi": "80",
    "‡§è‡§ï‡§æ‡§∏‡•Ä": "81",
    "‡§¨‡§Ø‡§æ‡§∏‡•Ä": "82",
    "‡§§‡•ç‡§∞‡§ø‡§Ø‡§æ‡§∏‡•Ä": "83",
    "‡§ö‡•å‡§∞‡§æ‡§∏‡•Ä": "84",
    "‡§™‡§ö‡§æ‡§∏‡•Ä": "85", "‡§™‡§ö‡§æ‡§∏‡§ø": "85",
    "‡§õ‡§Ø‡§æ‡§∏‡•Ä": "86",
    "‡§∏‡§§‡•ç‡§Ø‡§æ‡§∏‡•Ä": "87",
    "‡§Ö‡§†‡§æ‡§∏‡•Ä": "88",
    "‡§â‡§®‡§æ‡§®‡•ç‡§®‡§¨‡•ç‡§¨‡•á": "89",

    "‡§®‡§¨‡•ç‡§¨‡•á": "90", "nabbe": "90",
    "‡§è‡§ï‡§æ‡§®‡§¨‡•ç‡§¨‡•á": "91",
    "‡§¨‡§Ø‡§æ‡§®‡§¨‡•ç‡§¨‡•á": "92",
    "‡§§‡•ç‡§∞‡§ø‡§Ø‡§æ‡§®‡§¨‡•ç‡§¨‡•á": "93",
    "‡§ö‡•å‡§∞‡§æ‡§®‡§¨‡•ç‡§¨‡•á": "94",
    "‡§™‡§ö‡§æ‡§®‡§¨‡•ç‡§¨‡•á": "95", "pachanabbe": "95",
    "‡§õ‡§Ø‡§æ‡§®‡§¨‡•ç‡§¨‡•á": "96",
    "‡§∏‡§§‡•ç‡§Ø‡§æ‡§®‡§¨‡•ç‡§¨‡•á": "97",
    "‡§Ö‡§®‡•ç‡§†‡§æ‡§®‡§¨‡•ç‡§¨‡•á": "98",
    "‡§â‡§®‡§æ‡§®‡•ç‡§∏‡§Ø": "99",

    "‡§∏‡§Ø": "100", "‡§è‡§ï‡§∏‡§Ø": "100", "say": "100",

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # UNITS
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    "‡§ï‡§ø‡§≤‡•ã‡§ó‡•ç‡§∞‡§æ‡§Æ": "kg", "‡§ï‡§ø‡§≤‡•ã‡§ó": "kg", "‡§ï‡§ø‡§≤‡•ã": "kg", "‡§ï‡§ø‡§≤‡•Å": "kg",
    "kilo": "kg", "killo": "kg", "kilu": "kg", "kilogram": "kg",

    "‡§∏‡•ã‡§ü‡§æ": "pieces", "‡§ì‡§ü‡§æ": "pieces", "‡§ì‡§§‡§æ": "pieces",
    "‡§µ‡§ü‡§æ": "pieces", "‡§µ‡§æ‡§ü‡§æ": "pieces", "‡§≠‡§ü‡§æ": "pieces",
    "‡§ó‡•ã‡§ü‡§æ": "pieces", "‡§ó‡•ã‡§ü‡•ã": "pieces",
    "wata": "pieces", "ota": "pieces", "vata": "pieces",
    "gota": "pieces", "bata": "pieces", "otta": "pieces",
    "piece": "pieces", "pieces": "pieces",

    "‡§™‡•ç‡§Ø‡§æ‡§ï‡•á‡§ü": "packet", "‡§™‡•ç‡§Ø‡§æ‡§ï‡•á‡§ü‡§π‡§∞‡•Ç": "packet",
    "‡§™‡•ã‡§ï‡§æ": "packet", "‡§™‡•ã‡§ï‡•ã": "packet", "‡§™‡§ï‡•á‡§ü": "packet",
    "packet": "packet", "packets": "packet",
    "pakit": "packet", "pyaket": "packet", "poka": "packet",

    "‡§≤‡§ø‡§ü‡§∞": "liter", "‡§≤‡§ø‡§ü‡§∞‡§π‡§∞‡•Ç": "liter", "‡§≤‡§ø‡§ü‡§æ‡§∞": "liter",
    "liter": "liter", "litre": "liter", "litar": "liter",
    "liters": "liter", "litres": "liter",

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # ITEMS ‚Äî DEVANAGARI
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    # Rice ‚Äî ‡§ö‡§æ‡§Æ‡§≤
    "‡§ö‡§æ‡§Æ‡§≤": "Rice", "‡§ö‡§æ‡§æ‡§Æ‡§≤": "Rice", "‡§ö‡§æ‡§Æ": "Rice",
    "‡§ö‡§æ‡§Æ‡§≤‡•ç": "Rice", "‡§ö‡§æ‡§Æ‡§æ‡§≤": "Rice", "‡§ö‡§æ‡§Æ‡§≤‡•á": "Rice",

    # Lentils ‚Äî ‡§¶‡§æ‡§≤ / ‡§°‡§æ‡§≤
    "‡§¶‡§æ‡§≤": "Lentils", "‡§°‡§æ‡§≤": "Lentils",
    "‡§¶‡§æ‡§≤‡•ç": "Lentils", "‡§¶‡§æ‡§≤‡§π‡§∞‡•Ç": "Lentils", "‡§¶‡§æ‡§≤‡•á": "Lentils",

    # Salt ‚Äî ‡§®‡•Å‡§®
    "‡§®‡•Å‡§®": "Salt", "‡§®‡•Ç‡§®": "Salt", "‡§®‡•Å‡§®‡•ç": "Salt",
    "‡§®‡•Å‡§®‡•á": "Salt", "‡§®‡•Å‡§®‡•Å": "Salt",

    # Sugar ‚Äî ‡§ö‡§ø‡§®‡•Ä / ‡§ö‡§ø‡§®‡§ø
    "‡§ö‡§ø‡§®‡•Ä": "Sugar", "‡§ö‡§ø‡§®‡§ø": "Sugar", "‡§ö‡§ø‡§®‡§ø‡§É": "Sugar",
    "‡§ö‡§ø‡§®‡§ø‡§π‡§∞‡•Ç": "Sugar", "‡§ö‡§ø‡§®‡•ç": "Sugar", "‡§ö‡§ø‡§®‡•ã": "Sugar",

    # Oil ‚Äî ‡§§‡•á‡§≤
    "‡§§‡•á‡§≤": "Oil", "‡§§‡•á‡§≤‡•ç": "Oil", "‡§§‡•á‡§≤‡§π‡§∞‡•Ç": "Oil",
    "‡§§‡•à‡§≤": "Oil", "‡§§‡•á‡§≤‡•ã": "Oil",

    # Flour ‚Äî ‡§Æ‡•à‡§¶‡§æ + ALL ‡§Æ-mishears (‡§Æ is unique first char)
    "‡§Æ‡•à‡§¶‡§æ": "Flour", "‡§Æ‡§π‡§ø‡§¶‡§æ": "Flour", "‡§Æ‡•á‡§¶‡§æ": "Flour",
    "‡§Æ‡§á‡§¶‡§æ": "Flour", "‡§Æ‡§æ‡§á‡§¶‡§æ": "Flour", "‡§Æ‡§à‡§¶‡§æ": "Flour",
    "‡§Æ‡•á‡§á‡§¶‡§æ": "Flour", "‡§Æ‡•á‡§π‡§ø‡§¶‡§æ": "Flour", "‡§Æ‡§æ‡§á‡§¶‡§æ‡§æ": "Flour",
    "‡§Æ‡•à‡§¶‡•ã": "Flour", "‡§Æ‡•à‡§¶‡§æ‡§æ": "Flour", "‡§Æ‡•à‡§ø‡§¶‡§æ": "Flour", "‡§Æ‡§ø‡§¶‡§æ": "Flour",

    # Turmeric ‚Äî ‡§¨‡•á‡§∏‡§æ‡§∞ / ‡§µ‡•á‡§∏‡§æ‡§∞
    "‡§¨‡•á‡§∏‡§æ‡§∞": "Turmeric", "‡§¨‡•á‡§∏‡§æ‡§°": "Turmeric", "‡§¨‡•á‡§∏‡§æ‡§∞‡•ç": "Turmeric",
    "‡§¨‡•á‡§∏‡§æ‡§∞‡§π‡§∞‡•Ç": "Turmeric", "‡§¨‡•á‡§∏‡§æ‡§æ‡§∞‡§æ": "Turmeric", "‡§¨‡•á‡§∏‡§æ‡§∞‡•ã": "Turmeric",
    "‡§µ‡•á‡§∏‡§æ‡§∞": "Turmeric", "‡§µ‡•á‡§∏‡§æ‡§°": "Turmeric", "‡§µ‡•á‡§∏‡§æ‡§∞‡•Å": "Turmeric",

    # Eggs ‚Äî ‡§Ö‡§£‡•ç‡§°‡§æ / ‡§Ö‡§®‡•ç‡§°‡§æ / ‡§Ö‡§Ç‡§°‡§æ (common alternate with anusvara)
    "‡§Ö‡§£‡•ç‡§°‡§æ": "Eggs", "‡§Ö‡§®‡•ç‡§°‡§æ": "Eggs", "‡§Ö‡§°‡§º‡§æ": "Eggs",
    "‡§Ö‡§®‡•ç‡§°‡•ã": "Eggs", "‡§Ö‡§®‡•ç‡§°‡§æ‡§π‡§∞‡•Ç": "Eggs", "‡§Ö‡§£‡•ç‡§°‡•ã": "Eggs",
    "‡§Ö‡§æ‡§£‡•ç‡§°‡§æ": "Eggs", "‡§Ö‡§®‡•ç‡§°‡•á": "Eggs",
    "‡§Ö‡§Ç‡§°‡§æ": "Eggs",   # ‚Üê anusvara form Whisper commonly outputs

    # Beaten_Rice ‚Äî ‡§ö‡§ø‡§â‡§∞‡§æ
    "‡§ö‡§ø‡§â‡§∞‡§æ": "Beaten_Rice", "‡§ö‡§ø‡§â‡§∞‡•ã": "Beaten_Rice",
    "‡§ö‡§ø‡§â‡§∞‡§æ‡§π‡§∞‡•Ç": "Beaten_Rice", "‡§ö‡§ø‡§â‡§∞": "Beaten_Rice",

    # Biscuits ‚Äî ‡§¨‡§ø‡§∏‡•ç‡§ï‡•Å‡§ü / ‡§¨‡§ø‡§∏‡•ç‡§ï‡§ø‡§ü
    "‡§¨‡§ø‡§∏‡•ç‡§ï‡•Å‡§ü": "Biscuits", "‡§¨‡§ø‡§∏‡•ç‡§ï‡§ø‡§ü": "Biscuits",
    "‡§¨‡§ø‡§∏‡•ç‡§ï‡•Å‡§ü‡•ç": "Biscuits", "‡§¨‡§ø‡§∏‡•ç‡§ï‡•Å‡§ü‡§π‡§∞‡•Ç": "Biscuits",
    "‡§¨‡§ø‡§∏‡•ç‡§ï‡§ø‡§ü‡§π‡§∞‡•Ç": "Biscuits", "‡§¨‡§ø‡§∏‡•ç‡§ï‡•ã‡§ü": "Biscuits",

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # ITEMS ‚Äî ROMANIZED
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    "chamal": "Rice", "chaamal": "Rice", "chaaml": "Rice",
    "ryce": "Rice", "samal": "Rice", "rice": "Rice",

    "daal": "Lentils", "dal": "Lentils", "dhal": "Lentils",
    "daall": "Lentils", "lentils": "Lentils", "lentil": "Lentils",

    "nun": "Salt", "noon": "Salt", "nune": "Salt",
    "nunu": "Salt", "nuun": "Salt", "salt": "Salt",

    "cheeni": "Sugar", "chini": "Sugar", "sini": "Sugar",
    "chene": "Sugar", "cheene": "Sugar", "chine": "Sugar", "sugar": "Sugar",

    "tel": "Oil", "tail": "Oil", "tayl": "Oil",
    "teel": "Oil", "tell": "Oil", "oil": "Oil",

    "maida": "Flour", "mahida": "Flour", "maeda": "Flour",
    "maita": "Flour", "meda": "Flour", "mayda": "Flour",
    "meida": "Flour", "maheda": "Flour", "flour": "Flour",

    "besar": "Turmeric", "besaar": "Turmeric", "beasar": "Turmeric",
    "beasaar": "Turmeric", "turmeric": "Turmeric", "haldi": "Turmeric",

    "anda": "Eggs", "unda": "Eggs", "ando": "Eggs",
    "aanda": "Eggs", "eggs": "Eggs", "egg": "Eggs",

    "chiura": "Beaten_Rice", "chiuraa": "Beaten_Rice",
    "chiora": "Beaten_Rice", "chiuro": "Beaten_Rice",
    "beaten rice": "Beaten_Rice", "beaten_rice": "Beaten_Rice",

    "biskut": "Biscuits", "biscut": "Biscuits",
    "biscuit": "Biscuits", "biscuits": "Biscuits", "biskutt": "Biscuits",

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # ACTIONS ‚Äî DEVANAGARI
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    # REMOVE ‚Äî stock DOWN
    "‡§ò‡§ü‡§æ‡§â": "Remove", "‡§ò‡§ü‡§æ‡§â‡§Å": "Remove", "‡§ò‡§ü‡§æ‡§Ø‡•ã": "Remove",
    "‡§ò‡§ü‡§æ‡§á": "Remove", "‡§ò‡§ü‡§æ": "Remove", "‡§ò‡§ü‡§æ‡§µ": "Remove",
    "‡§ò‡§ü‡§æ‡§â‡§õ": "Remove", "‡§ò‡§ü‡§æ‡§â‡§®‡•Å": "Remove",
    "‡§ó‡§ü‡§æ‡§â": "Remove",        # Whisper mishear of ‡§ò‡§ü‡§æ‡§â
    "‡§Ö‡§ü‡§æ‡§µ": "Remove",        # Whisper hallucination
    "‡§¨‡•á‡§ö‡•ç‡§Ø‡•ã": "Remove", "‡§¨‡•á‡§ö": "Remove", "‡§¨‡•á‡§ö‡§ø‡§®‡•ç‡§õ": "Remove",
    "‡§π‡§ü‡§æ‡§â": "Remove", "‡§π‡§ü‡§æ": "Remove", "‡§π‡§ü‡§æ‡§Ø‡•ã": "Remove",
    "‡§®‡§ø‡§ï‡§æ‡§≤": "Remove", "‡§®‡§ø‡§ï‡§æ‡§≤‡•ç‡§Ø‡•ã": "Remove",
    "‡§ñ‡§∞‡•ç‡§ö": "Remove", "‡§ñ‡§∞‡•ç‡§ö‡•ç‡§Ø‡•ã": "Remove",
    "‡§¨‡§ø‡§ï‡•ç‡§Ø‡•ã": "Remove", "‡§¨‡§ø‡§ï‡•ç‡§∞‡•Ä": "Remove",

    # ADD ‚Äî stock UP
    "‡§¨‡§¢‡§æ‡§â": "Add", "‡§¨‡§¢‡§æ‡§â‡§Å": "Add", "‡§¨‡§¢‡§æ‡§Ø‡•ã": "Add",
    "‡§¨‡§¢‡§æ‡§á": "Add", "‡§¨‡§¢‡§æ": "Add", "‡§¨‡§¢‡•ç‡§Ø‡•ã": "Add",
    "‡§¨‡§¢‡§æ‡§â‡§õ": "Add", "‡§¨‡§¢‡§æ‡§â‡§®‡•Å": "Add",
    "‡§•‡§™‡•ç‡§Ø‡•ã": "Add", "‡§•‡§™‡§æ": "Add", "‡§•‡§æ‡§™‡§æ": "Add", "‡§•‡§™": "Add", "‡§ß‡§™‡§æ": "Add", "‡§•‡§æ‡§µ‡§æ": "Add",
    "‡§•‡§™‡§ø‡§®‡•ç‡§õ": "Add", "‡§•‡§™‡§ø‡§Ø‡•ã": "Add",
    "‡§ï‡§ø‡§®‡•ç‡§Ø‡•ã": "Add", "‡§ï‡§ø‡§®‡•ç‡§õ‡•Å": "Add", "‡§ï‡§ø‡§®‡•ç‡§Ø‡•å‡§Ç": "Add",
    "‡§∞‡§æ‡§ñ‡•ç‡§Ø‡•ã": "Add", "‡§∞‡§æ‡§ñ": "Add", "‡§∞‡§æ‡§ñ‡§ø‡§Ø‡•ã": "Add",
    "‡§Ü‡§Ø‡•ã": "Add", "‡§Ü‡§â‡§Å‡§õ": "Add",

    # CHECK ‚Äî query stock
    "‡§¨‡§æ‡§Å‡§ï‡•Ä": "Check", "‡§¨‡§æ‡§Å‡§ï‡§ø": "Check", "‡§¨‡§æ‡§ï‡•Ä": "Check",
    "‡§¨‡§æ‡§ó‡•Ä": "Check",          # real log mishear of ‡§¨‡§æ‡§Å‡§ï‡•Ä
    "‡§¨‡§æ‡§Å‡§ï‡§ø‡§õ": "Check", "‡§¨‡§æ‡§Å‡§ï‡§ø‡§õ‡§®‡•ç": "Check",
    "‡§ï‡§§‡§ø": "Check", "‡§ï‡§§‡§ø‡§µ‡§ü‡§æ": "Check", "‡§ï‡§§‡§ø‡§ì‡§ü‡§æ": "Check",
    "‡§ï‡•ã‡§ü‡•Ä": "Check",          # real log mishear of ‡§ï‡§§‡§ø
    "‡§ï‡•ã‡§§‡•Ä": "Check",
    "‡§õ‡§æ‡§Å": "Check",           # trailing "‡§õ" in "‡§ï‡§§‡§ø ‡§¨‡§æ‡§Å‡§ï‡•Ä ‡§õ"
    "‡§õ‡§®‡•ç": "Check",
    "‡§ö‡•á‡§ï": "Check", "‡§∏‡•ç‡§ü‡§ï": "Check",

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # ACTIONS ‚Äî ROMANIZED
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

    "ghatau": "Remove", "ghataau": "Remove", "ghata": "Remove",
    "ghatayo": "Remove", "ghatai": "Remove",
    "bech": "Remove", "bechyo": "Remove",
    "hatau": "Remove", "hatayo": "Remove",
    "nikal": "Remove", "nikalyo": "Remove",
    "kharch": "Remove", "kharchyo": "Remove",
    "bikyo": "Remove", "bikri": "Remove",
    "remove": "Remove", "sell": "Remove", "sold": "Remove",
    "decrease": "Remove", "reduce": "Remove",

    "badhau": "Add", "badhaau": "Add", "badhayo": "Add",
    "badha": "Add", "badhyo": "Add", "badhaaou": "Add",
    "thap": "Add", "thapaau": "Add", "thapyo": "Add",
    "kinyo": "Add", "kinchhau": "Add",
    "rakh": "Add", "rakhyo": "Add",
    "aayo": "Add", "aaucha": "Add",
    "add": "Add", "increase": "Add", "bought": "Add",

    "banki": "Check", "baaki": "Check", "baki": "Check",
    "baagi": "Check",
    "kati": "Check", "katiwata": "Check",
    "koti": "Check",
    "check": "Check", "stock": "Check",
    "how much": "Check", "how many": "Check",
}

# Quick lookup sets
_ITEMS   = {"Rice","Lentils","Salt","Sugar","Oil","Flour",
             "Turmeric","Eggs","Beaten_Rice","Biscuits"}
_ACTIONS = {"Add","Remove","Check"}
_UNITS   = {"kg","pieces","packet","liter"}


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# LAYER 2 ‚Äî DEVANAGARI PREFIX-TREE
# Safety net for any Devanagari word the dict missed.
# Number words are already replaced in Layer 1, so '‡§¶' here means Lentils.
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def _devanagari_prefix_match(word: str) -> str | None:
    w = word.strip("‡•§.,!? \t\n")
    if not w:
        return None

    c1 = w[0]
    c2 = w[1] if len(w) > 1 else ""
    c3 = w[2] if len(w) > 2 else ""

    # Unique first characters
    if c1 == "‡§Ö":           return "Eggs"
    if c1 == "‡§°":           return "Lentils"   # only ‡§° here ‚Äî not ‡§¶ (numbers caught in dict)
    if c1 == "‡§¶":           return "Lentils"   # ‡§¶‡§æ‡§≤; ‡§¶‡§∂/‡§¶‡§∏/‡§¶‡§æ‡§∏ already replaced in dict
    if c1 == "‡§§":           return "Oil"
    if c1 == "‡§®":           return "Salt"
    if c1 == "‡§Æ":           return "Flour"     # ALL ‡§ÆX ‚Üí Flour (unique)
    if c1 == "‡§µ":           return "Turmeric"  # ‡§µ‡•á‡§∏‡§æ‡§∞ alternate

    # ‡§ö ‚Äî needs 2nd char
    if c1 == "‡§ö":
        if c2 == "‡§æ":       return "Rice"          # ‡§ö‡§æ ‚Üí ‡§ö‡§æ‡§Æ‡§≤
        if c2 == "‡§ø":
            if c3 == "‡§®":   return "Sugar"          # ‡§ö‡§ø‡§® ‚Üí ‡§ö‡§ø‡§®‡•Ä
            return "Beaten_Rice"                    # ‡§ö‡§ø‡§â/‡§ö‡§ø‡•ã ‚Üí ‡§ö‡§ø‡§â‡§∞‡§æ
        return "Rice"                               # fallback ‡§öX

    # ‡§¨ ‚Äî needs 2nd char
    if c1 == "‡§¨":
        if c2 == "‡•á":       return "Turmeric"       # ‡§¨‡•á ‚Üí ‡§¨‡•á‡§∏‡§æ‡§∞
        if c2 == "‡§ø":       return "Biscuits"       # ‡§¨‡§ø ‚Üí ‡§¨‡§ø‡§∏‡•ç‡§ï‡•Å‡§ü
        if c2 == "‡§¢":       return "Add"            # ‡§¨‡§¢ ‚Üí ‡§¨‡§¢‡§æ‡§â verb
        if c2 == "‡§æ":       return "Check"          # ‡§¨‡§æ‡§Å‡§ï‡•Ä (should be in dict but safety)

    return None


def _is_devanagari(s: str) -> bool:
    return any("\u0900" <= ch <= "\u097F" for ch in s)


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# WHISPER SERVICE
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class WhisperService:
    def __init__(self):
        print("üîÑ Loading Whisper model (medium)...")
        self.model = whisper.load_model("medium")
        print("‚úÖ Whisper Loaded Successfully")

    def _clean(self, text: str) -> str:
        """
        Full cleaning pipeline:
          Step 0: Devanagari numeral chars ‚Üí Arabic  (‡•ß‡•¶ ‚Üí 10, infinite numbers)
          Step 1: Normalise punctuation
          Step 2: Layer 1 dict (longest key first)
          Step 3: Layer 2 prefix-tree for remaining Devanagari
          Step 4: Rebuild with canonical casing
          Step 5: Deduplicate repeated action tokens
        """

        # ‚îÄ‚îÄ Step 0: Devanagari digits ‚Üí Arabic digits ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        # Must run BEFORE any other step so ‡•ß‡•¶ ‚Üí 10 before dict sees it
        text = _convert_devanagari_numerals(text)

        # ‚îÄ‚îÄ Step 1: Normalise punctuation ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        for ch in "‡•§.,!?":
            text = text.replace(ch, " ")

        # ‚îÄ‚îÄ Step 2: Layer 1 exact dict ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        # Longest key first prevents partial matches (e.g. "paanch" before "pan")
        lowered = text.lower()

        for key in sorted(CORRECTIONS.keys(), key=len, reverse=True):
            val     = CORRECTIONS[key]
            lowered = lowered.replace(key.lower(), f" {val.lower()} ")
            text    = text.replace(key, f" {val} ")

        # ‚îÄ‚îÄ Step 3: Layer 2 prefix-tree for leftover Devanagari ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        tokens   = text.split()
        resolved = []
        for tok in tokens:
            t = tok.strip()
            if _is_devanagari(t):
                match = _devanagari_prefix_match(t)
                if match:
                    print(f"   üå≥ Prefix-tree: '{t}' ‚Üí '{match}'")
                    resolved.append(match.lower())
                else:
                    print(f"   ‚ùì Dropping unrecognised Devanagari: '{t}'")
                    # Intentionally not appended ‚Äî it's noise
            else:
                resolved.append(t.lower())

        # Merge prefix-tree output back into lowered
        lowered = " ".join(resolved)

        # ‚îÄ‚îÄ Step 4: Rebuild with proper capitalisation ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        final = []
        for w in lowered.split():
            w = w.strip()
            if not w:
                continue
            if w == "beaten_rice":
                final.append("Beaten_Rice")
            elif w in {i.lower() for i in _ITEMS}:
                final.append(w.capitalize())
            elif w in {a.lower() for a in _ACTIONS}:
                final.append(w.capitalize())
            elif w in _UNITS or w.isdigit():
                final.append(w)
            else:
                final.append(w)

        # ‚îÄ‚îÄ Step 5: Deduplicate consecutive identical action tokens ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        # e.g. "Flour Check Check Check" (from ‡§ï‡•ã‡§ü‡•Ä ‡§¨‡§æ‡§ó‡•Ä ‡§õ‡§æ‡§Å) ‚Üí "Flour Check"
        deduped = []
        prev    = None
        for w in final:
            if w in _ACTIONS and w == prev:
                continue
            deduped.append(w)
            prev = w

        result = " ".join(w for w in deduped if w)
        result = " ".join(result.split())
        return result

    def transcribe(self, audio_path: str) -> str:
        """
        Transcribe Nepali audio ‚Üí cleaned English-token string.
        """
        initial_prompt = (
            "chamal daal nun chini tel maida besar anda chiura biskut "
            "‡§ö‡§æ‡§Æ‡§≤ ‡§¶‡§æ‡§≤ ‡§®‡•Å‡§® ‡§ö‡§ø‡§®‡•Ä ‡§§‡•á‡§≤ ‡§Æ‡•à‡§¶‡§æ ‡§¨‡•á‡§∏‡§æ‡§∞ ‡§Ö‡§£‡•ç‡§°‡§æ ‡§ö‡§ø‡§â‡§∞‡§æ ‡§¨‡§ø‡§∏‡•ç‡§ï‡•Å‡§ü "
            "thap badhau ghatau check add remove "
            "‡§•‡§™ ‡§¨‡§¢‡§æ‡§â ‡§ò‡§ü‡§æ‡§â ‡§¨‡§æ‡§Å‡§ï‡•Ä ‡§ï‡§§‡§ø "
            "ek dui tin char paanch 1 2 3 4 5 6 7 8 9 10 "
            "kilo wata packet liter kg pieces "
            "‡§ï‡§ø‡§≤‡•ã ‡§µ‡§ü‡§æ ‡§™‡•ç‡§Ø‡§æ‡§ï‡•á‡§ü ‡§≤‡§ø‡§ü‡§∞"
        )

        result = self.model.transcribe(
            audio_path,
            language="ne",
            initial_prompt=initial_prompt,
            task="transcribe",
            beam_size=8,
            temperature=0.0,
            fp16=False,
            condition_on_previous_text=False,
            no_speech_threshold=0.6,
            compression_ratio_threshold=2.4,
        )

        raw_text = result["text"].strip()
        if len(raw_text) < 2:
            return ""

        cleaned = self._clean(raw_text)
        print(f"üéôÔ∏è  RAW     : {raw_text!r}")
        print(f"‚úÖ  CLEANED : {cleaned!r}")

        return cleaned