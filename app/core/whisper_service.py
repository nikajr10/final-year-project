import re
import whisper


class WhisperService:
    def __init__(self):
        print("üîÑ Loading Whisper model (medium)...")
        self.model = whisper.load_model("medium")
        print("‚úÖ Whisper Loaded Successfully")

    def _apply_brute_force_corrections(self, text: str) -> str:
        """
        THE IRON DICTIONARY
        =====================
        Every known Devanagari script word, every Romanized phonetic spelling,
        and every hallucination variant is mapped to one clean canonical English token.

        CANONICAL TOKENS (what the LLM will always receive):
          Numbers  : 1 2 3 4 5 6 7 8 9 10
          Units    : kg  pieces  packet  liter
          Items    : Rice  Lentils  Salt  Sugar  Oil  Flour
                     Turmeric  Eggs  Beaten_Rice  Biscuits
          Actions  : Add  Remove  Check
        """

        corrections = {

            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # NUMBERS
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

            # 1 ‚Äî ek / aek / ‡§è‡§ï / ‡§è‡§â‡§ü‡§æ
            "‡§è‡§â‡§ü‡§æ": "1", "‡§è‡§ï": "1",
            "ek": "1", "aek": "1", "euta": "1",

            # 2 ‚Äî dui / do / ‡§¶‡•Å‡§à / ‡§¶‡•ã / ‡§¶‡•Å‡§á‡§ü‡§æ
            "‡§¶‡•Å‡§á‡§ü‡§æ": "2", "‡§¶‡•Å‡§à": "2", "‡§¶‡•ã": "2",
            "dui": "2", "do": "2", "duitaa": "2",

            # 3 ‚Äî teen / tin / ‡§§‡•Ä‡§® / ‡§§‡§ø‡§®
            "‡§§‡•Ä‡§®": "3", "‡§§‡§ø‡§®": "3",
            "teen": "3", "tin": "3",

            # 4 ‚Äî char / chaar / ‡§ö‡§æ‡§∞
            "‡§ö‡§æ‡§∞": "4",
            "char": "4", "chaar": "4",

            # 5 ‚Äî paanch / panch / ‡§™‡§æ‡§Å‡§ö / ‡§™‡§æ‡§ö / ‡§™‡§æ‡§•‡•ç‡§∏ (hallucination)
            "‡§™‡§æ‡§Å‡§ö": "5", "‡§™‡§æ‡§ö": "5", "‡§™‡§æ‡§•‡•ç‡§∏": "5", "‡§™‡§æ‡§Å‡§ö": "5",
            "paanch": "5", "panch": "5", "paach": "5",

            # 6 ‚Äî cha / chha / ‡§õ
            "‡§õ": "6",
            "cha": "6", "chha": "6", "chah": "6",

            # 7 ‚Äî saat / sat / ‡§∏‡§æ‡§§
            "‡§∏‡§æ‡§§": "7",
            "saat": "7", "sat": "7",

            # 8 ‚Äî aath / ath / ‡§Ü‡§†
            "‡§Ü‡§†": "8",
            "aath": "8", "ath": "8", "aate": "8",

            # 9 ‚Äî nau / naw / ‡§®‡•å   (never map standalone "no" ‚Äî too ambiguous)
            "‡§®‡•å": "9",
            "nau": "9", "naw": "9", "noo": "9",

            # 10 ‚Äî das / dass / ‡§¶‡§∏ / ‡§¶‡§∂ / ‡§¶‡§æ‡§∏ (hallucination)
            "‡§¶‡§æ‡§∏": "10", "‡§¶‡§∂": "10", "‡§¶‡§∏": "10",
            "das": "10", "dass": "10", "dasa": "10",

            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # UNITS
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

            # kg / kilo ‚Äî ‡§ï‡§ø‡§≤‡•ã / ‡§ï‡§ø‡§≤‡•ã‡§ó (hallucination)
            "‡§ï‡§ø‡§≤‡•ã‡§ó": "kg", "‡§ï‡§ø‡§≤‡•ã": "kg",
            "kilo": "kg", "killo": "kg", "kilu": "kg",

            # pieces / wata / ota ‚Äî ‡§µ‡§ü‡§æ / ‡§ì‡§ü‡§æ / ‡§ì‡§§‡§æ / ‡§∏‡•ã‡§ü‡§æ (hallucination)
            "‡§∏‡•ã‡§ü‡§æ": "pieces", "‡§ì‡§ü‡§æ": "pieces", "‡§ì‡§§‡§æ": "pieces", "‡§µ‡§ü‡§æ": "pieces",
            "wata": "pieces", "ota": "pieces", "vata": "pieces", "bata": "pieces",
            "gota": "pieces", "otta": "pieces",

            # packet ‚Äî ‡§™‡•ç‡§Ø‡§æ‡§ï‡•á‡§ü / ‡§™‡•ã‡§ï‡§æ
            "‡§™‡•ç‡§Ø‡§æ‡§ï‡•á‡§ü": "packet", "‡§™‡•ã‡§ï‡§æ": "packet",
            "packet": "packet", "pakit": "packet", "pyaket": "packet",

            # liter ‚Äî ‡§≤‡§ø‡§ü‡§∞
            "‡§≤‡§ø‡§ü‡§∞": "liter",
            "liter": "liter", "litre": "liter", "litar": "liter",

            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # ITEMS  (10 canonical items)
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

            # Rice ‚Äî ‡§ö‡§æ‡§Æ‡§≤ / ryce / samal / chamal (hallucinations)
            "‡§ö‡§æ‡§Æ‡§≤": "Rice", "‡§ö‡§æ‡§Æ": "Rice",
            "chamal": "Rice", "chaamal": "Rice", "ryce": "Rice",
            "samal": "Rice", "chamaL": "Rice",
            "rice": "Rice",

            # Lentils ‚Äî ‡§¶‡§æ‡§≤ / ‡§°‡§æ‡§≤ / daal / dal
            "‡§¶‡§æ‡§≤": "Lentils", "‡§°‡§æ‡§≤": "Lentils",
            "daal": "Lentils", "dal": "Lentils", "dhal": "Lentils",
            "lentils": "Lentils",

            # Salt ‚Äî ‡§®‡•Å‡§® / noon / nun
            "‡§®‡•Å‡§®": "Salt",
            "nun": "Salt", "noon": "Salt", "nune": "Salt",
            "salt": "Salt",

            # Sugar ‚Äî ‡§ö‡§ø‡§®‡•Ä / ‡§ö‡§ø‡§®‡§ø / sini / chini
            "‡§ö‡§ø‡§®‡•Ä": "Sugar", "‡§ö‡§ø‡§®‡§ø": "Sugar",
            "chini": "Sugar", "sini": "Sugar", "cheeni": "Sugar", "chene": "Sugar",
            "sugar": "Sugar",

            # Oil ‚Äî ‡§§‡•á‡§≤ / tail / tel
            "‡§§‡•á‡§≤": "Oil",
            "tel": "Oil", "tail": "Oil", "tayl": "Oil",
            "oil": "Oil",

            # Flour ‚Äî ‡§Æ‡•à‡§¶‡§æ / maida
            "‡§Æ‡•à‡§¶‡§æ": "Flour",
            "maida": "Flour", "maeda": "Flour", "maita": "Flour",
            "flour": "Flour",

            # Turmeric ‚Äî ‡§¨‡•á‡§∏‡§æ‡§∞ / ‡§µ‡•á‡§∏‡§æ‡§∞ / besar / besaar
            "‡§¨‡•á‡§∏‡§æ‡§∞": "Turmeric", "‡§µ‡•á‡§∏‡§æ‡§∞": "Turmeric", "‡§¨‡•á‡§∏‡§æ‡§°": "Turmeric",
            "besar": "Turmeric", "besaar": "Turmeric", "beasar": "Turmeric",
            "turmeric": "Turmeric",

            # Eggs ‚Äî ‡§Ö‡§£‡•ç‡§°‡§æ / ‡§Ö‡§®‡•ç‡§°‡§æ / ‡§Ö‡§°‡§º‡§æ / anda
            "‡§Ö‡§£‡•ç‡§°‡§æ": "Eggs", "‡§Ö‡§®‡•ç‡§°‡§æ": "Eggs", "‡§Ö‡§°‡§º‡§æ": "Eggs", "‡§Ö‡§®‡•ç‡§°‡•ã": "Eggs",
            "anda": "Eggs", "unda": "Eggs", "ando": "Eggs",
            "eggs": "Eggs", "egg": "Eggs",

            # Beaten_Rice ‚Äî ‡§ö‡§ø‡§â‡§∞‡§æ / chiura
            "‡§ö‡§ø‡§â‡§∞‡§æ": "Beaten_Rice",
            "chiura": "Beaten_Rice", "chiuraa": "Beaten_Rice", "chiora": "Beaten_Rice",
            "beaten rice": "Beaten_Rice",

            # Biscuits ‚Äî ‡§¨‡§ø‡§∏‡•ç‡§ï‡•Å‡§ü / biskut
            "‡§¨‡§ø‡§∏‡•ç‡§ï‡•Å‡§ü": "Biscuits", "‡§¨‡§ø‡§∏‡•ç‡§ï‡§ø‡§ü": "Biscuits",
            "biskut": "Biscuits", "biscut": "Biscuits", "biscuit": "Biscuits",
            "biscuits": "Biscuits",

            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # ACTIONS / VERBS
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

            # ‚îÄ‚îÄ REMOVE (ghatau / ghataau) ‚Äî stock goes DOWN ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            # Devanagari
            "‡§ò‡§ü‡§æ‡§â": "Remove", "‡§ò‡§ü‡§æ‡§â‡§Å": "Remove", "‡§ò‡§ü‡§æ‡§Ø‡•ã": "Remove",
            "‡§ò‡§ü‡§æ‡§á": "Remove", "‡§ò‡§ü‡§æ": "Remove", "‡§ò‡§ü‡§æ‡§µ": "Remove",
            "‡§ó‡§ü‡§æ‡§â": "Remove",   # common Whisper mishear
            "‡§Ö‡§ü‡§æ‡§µ": "Remove",   # hallucination
            "‡§¨‡•á‡§ö‡•ç‡§Ø‡•ã": "Remove", "‡§¨‡•á‡§ö": "Remove", "‡§¨‡•á‡§ö‡§ø‡§®‡•ç‡§õ": "Remove",
            "‡§π‡§ü‡§æ‡§â": "Remove", "‡§π‡§ü‡§æ": "Remove", "‡§π‡§ü‡§æ‡§Ø‡•ã": "Remove",
            "‡§®‡§ø‡§ï‡§æ‡§≤": "Remove", "‡§®‡§ø‡§ï‡§æ‡§≤‡•ç‡§Ø‡•ã": "Remove",
            "‡§ñ‡§∞‡•ç‡§ö": "Remove", "‡§ñ‡§∞‡•ç‡§ö‡•ç‡§Ø‡•ã": "Remove",
            "‡§¨‡§ø‡§ï‡•ç‡§Ø‡•ã": "Remove", "‡§¨‡§ø‡§ï‡•ç‡§∞‡•Ä": "Remove",
            # Romanized
            "ghatau": "Remove", "ghataau": "Remove", "ghata": "Remove",
            "ghatayo": "Remove", "ghatai": "Remove",
            "bech": "Remove", "bechyo": "Remove",
            "hatau": "Remove", "hatayo": "Remove",
            "nikal": "Remove", "nikalyo": "Remove",
            "kharch": "Remove", "kharchyo": "Remove",
            "bikyo": "Remove", "bikri": "Remove",
            "remove": "Remove", "sell": "Remove", "sold": "Remove",
            "decrease": "Remove", "reduce": "Remove",

            # ‚îÄ‚îÄ ADD (badhau / thap) ‚Äî stock goes UP ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            # Devanagari
            "‡§¨‡§¢‡§æ‡§â": "Add", "‡§¨‡§¢‡§æ‡§â‡§Å": "Add", "‡§¨‡§¢‡§æ‡§Ø‡•ã": "Add",
            "‡§¨‡§¢‡§æ‡§á": "Add", "‡§¨‡§¢‡§æ": "Add", "‡§¨‡§¢‡•ç‡§Ø‡•ã": "Add",
            "‡§•‡§™‡•ç‡§Ø‡•ã": "Add", "‡§•‡§™‡§æ": "Add", "‡§•‡§™": "Add", "‡§ß‡§™‡§æ": "Add",
            "‡§ï‡§ø‡§®‡•ç‡§Ø‡•ã": "Add", "‡§ï‡§ø‡§®‡•ç‡§õ‡•Å": "Add", "‡§ï‡§ø‡§®‡•ç‡§Ø‡•å‡§Ç": "Add",
            "‡§∞‡§æ‡§ñ‡•ç‡§Ø‡•ã": "Add", "‡§∞‡§æ‡§ñ": "Add", "‡§∞‡§æ‡§ñ‡§ø‡§Ø‡•ã": "Add",
            "‡§Ü‡§Ø‡•ã": "Add", "‡§Ü‡§â‡§Å‡§õ": "Add",
            "‡§•‡§™‡§ø‡§®‡•ç‡§õ": "Add", "‡§•‡§™‡§ø‡§Ø‡•ã": "Add",
            # Romanized
            "badhau": "Add", "badhaau": "Add", "badhayo": "Add",
            "badha": "Add", "badhyo": "Add",
            "thap": "Add", "thapaau": "Add", "thapyo": "Add",
            "kinyo": "Add", "kinchhau": "Add",
            "rakh": "Add", "rakhyo": "Add",
            "aayo": "Add", "aaucha": "Add",
            "add": "Add", "increase": "Add", "bought": "Add",

            # ‚îÄ‚îÄ CHECK ‚Äî query current stock level ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
            # Devanagari
            "‡§¨‡§æ‡§Å‡§ï‡•Ä": "Check", "‡§¨‡§æ‡§Å‡§ï‡§ø": "Check",
            "‡§ï‡§§‡§ø": "Check", "‡§ï‡§§‡§ø‡§µ‡§ü‡§æ": "Check", "‡§ï‡§§‡§ø‡§ì‡§ü‡§æ": "Check",
            "‡§ö‡•á‡§ï": "Check", "‡§∏‡•ç‡§ü‡§ï": "Check",
            # Romanized
            "banki": "Check", "baaki": "Check", "baki": "Check",
            "kati": "Check", "katiwata": "Check",
            "check": "Check", "stock": "Check",
            "how much": "Check", "how many": "Check",
        }

        # ‚îÄ‚îÄ Step 1: Normalise punctuation ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        # Remove Devanagari da·πá·∏ça, periods, commas ‚Äî they confuse the LLM
        text = text.replace("‡•§", " ").replace(".", " ").replace(",", " ")

        # ‚îÄ‚îÄ Step 2: Lowercase a working copy for Romanized matches ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        # We do case-insensitive replacement by lowercasing text temporarily,
        # then applying canonical (properly cased) tokens.
        # Strategy: work on lowercased text so Romanized variants match regardless
        # of Whisper capitalisation.
        lowered = text.lower()

        # ‚îÄ‚îÄ Step 3: Apply corrections longest-key-first to avoid partial hits ‚îÄ‚îÄ
        # e.g. "paanch" must be replaced before "pan" or "cha"
        for bad_word in sorted(corrections.keys(), key=len, reverse=True):
            good_word = corrections[bad_word]
            # Replace in original text (for Devanagari, exact match)
            text = text.replace(bad_word, f" {good_word} ")
            # Replace in lowercased text (for Romanized variants)
            lowered = lowered.replace(bad_word.lower(), f" {good_word.lower()} ")

        # ‚îÄ‚îÄ Step 4: Reconcile ‚Äî for each Romanized canonical token in lowered,
        #            inject the properly-cased version into text ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        canonical_tokens = {
            "rice", "lentils", "salt", "sugar", "oil", "flour",
            "turmeric", "eggs", "beaten_rice", "biscuits",
            "add", "remove", "check",
            "kg", "pieces", "packet", "liter",
        }
        words_in_lowered = lowered.split()
        words_in_text   = text.split()

        # Rebuild from lowered (which has all replacements) ‚Äî capitalise items & actions
        final_words = []
        for w in words_in_lowered:
            clean = w.strip()
            if clean in {"rice","lentils","salt","sugar","oil","flour",
                         "turmeric","eggs","beaten_rice","biscuits"}:
                final_words.append(clean.capitalize() if "_" not in clean else "Beaten_Rice")
            elif clean in {"add","remove","check"}:
                final_words.append(clean.capitalize())
            elif clean.isdigit() or clean in {"kg","pieces","packet","liter"}:
                final_words.append(clean)
            else:
                final_words.append(clean)

        cleaned_text = " ".join(final_words)

        # ‚îÄ‚îÄ Step 5: Clean up extra whitespace ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        cleaned_text = " ".join(cleaned_text.split())

        return cleaned_text

    def transcribe(self, audio_path: str) -> str:
        """
        Transcribe Nepali audio and return a pre-cleaned English-token string.

        The initial_prompt biases Whisper toward the vocabulary we care about,
        reducing hallucinations of random Hindi/Sanskrit words.
        """
        # Prompt contains both Devanagari and Romanized versions of every key word
        # so Whisper's language model is primed before it hears a single audio frame.
        initial_prompt = (
            "chamal daal nun chini tel maida besar anda chiura biskut "
            "‡§ö‡§æ‡§Æ‡§≤ ‡§¶‡§æ‡§≤ ‡§®‡•Å‡§® ‡§ö‡§ø‡§®‡•Ä ‡§§‡•á‡§≤ ‡§Æ‡•à‡§¶‡§æ ‡§¨‡•á‡§∏‡§æ‡§∞ ‡§Ö‡§£‡•ç‡§°‡§æ ‡§ö‡§ø‡§â‡§∞‡§æ ‡§¨‡§ø‡§∏‡•ç‡§ï‡•Å‡§ü "
            "thap badhau ghatau check add remove "
            "‡§•‡§™ ‡§¨‡§¢‡§æ‡§â ‡§ò‡§ü‡§æ‡§â ‡§¨‡§æ‡§Å‡§ï‡•Ä ‡§ï‡§§‡§ø "
            "ek dui tin char paanch 1 2 3 4 5 6 7 8 9 10 "
            "kilo wata packet liter kg pieces "
            "‡§ï‡§ø‡§≤‡•ã ‡§µ‡§ü‡§æ ‡§™‡•ç‡§Ø‡§æ‡§ï‡•á‡§ü ‡§≤‡§ø‡§ü‡§∞"
        )

        result = self.model.transcribe(
            audio_path,
            language="ne",
            initial_prompt=initial_prompt,
            task="transcribe",
            beam_size=8,
            temperature=0.0,
            fp16=False,
            condition_on_previous_text=False,   # prevent hallucination loops
            no_speech_threshold=0.6,
            compression_ratio_threshold=2.4,
        )

        raw_text = result["text"].strip()
        if len(raw_text) < 2:
            return ""

        cleaned_text = self._apply_brute_force_corrections(raw_text)
        print(f"üõ†Ô∏è  RAW      : {raw_text!r}")
        print(f"‚úÖ  CLEANED  : {cleaned_text!r}")

        return cleaned_text